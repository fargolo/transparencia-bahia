---
title: "Web Scraping - Despesas dos Municípios do Estado da Bahia, via site do Tribunal de Contas dos Municípios do Estado da Bahia - TCM-Ba"
author: "George Santiago"
date: "18 de julho de 2018"
output: html_document
---

# Sobre a proposta e objetivo do Web Scraping


# Sobre o Código do Web Scraping em Linguagem R


## Etapas e Estratégias do Web Scraping


## Estrutura do Código em Linguagem R do Web Scraping


### Código do Web Scraping em Linguagem R 
- Carregar os pacotes utilizados no script

Nessa etapa, iremos carregar os pacotes utilizadas em todo o Web Scraping, bem como definir o diretório de trabalho, que é de fundamental importância na etapa de criação das pastas para armazenamento dos dados obtidos. Se os pacotes não estivem instalados na máquina, será necessário utilizar o comando *install.packages("nome_do_pacote")* para que consiga ser carregado com na função *library()*


```{r setup, include=FALSE}

# Carregar pacotes utilizados no Web Scraping

# Pacote de Documentação do Web Scraping
if(require(rmarkdown) == FALSE) { install.packages("rmarkdown")}

#bPacotes que serão usados no processo de Web Scraping
if(require(httr) == FALSE) {install.packages("httr")}
if(require(rvest) == FALSE) {install.packages("rvest")}
if(require(xml2) == FALSE) {install.packages("xml2")}

# Pacote que será usado como ´timer´ para disparara a execução do Scraping em determinado dia e hora
#if(require(cronr) == FALSE) {install.packages("cronr")} - esse pacote ainda não está disponível para a a versão 3.5 do R

# Pacotes que serão usados na criação das tabela (data frames) e no durante o processo de tramento de dados (Data Wrangling)
if(require(tibble) == FALSE) { install.packages("tibble")}
if(require(readr) == FALSE) { install.packages("readr")}
if(require(dplyr) == FALSE) { install.packages("dplyr")}
if(require(tidyr) == FALSE) { install.packages("tidyr")}
if(require(stringr) == FALSE) { install.packages("stringr")}
if(require(stringi) == FALSE) { install.packages("stringi")}
if(require(lubridate) == FALSE) { install.packages("lubridate")}

# Pacotes que serão usados iterar (realizar os loops) das funções e paralelizar a execução do código
if(require(purrr) == FALSE) { install.packages("purrr")}
if(require(furrr) == FALSE) { install.packages("furrr")}

# Pacotes que serão usados para comunir com o Banco de Dados
if(require(DBI) == FALSE) { install.packages("DBI")}
if(require(RSQLite) == FALSE) { install.packages("RSQLite")}

# Pacotes que gera código Hash dos arquivos HTML baixados
if(require(git2r) == FALSE) { install.packages("git2r")}

# Pacote que será usado para disponibilizar os dados via API Rest 
if(require(plumber) == FALSE) { install.packages("plumber")}

# Pacotes que serão usados para construir, via Dockerfile, a arquitetura para execução do Web Scraping em "nuvem
if(require(packrat) == FALSE) { install.packages("packrat")}
#if(require(containerit) == FALSE) { install.packages("containerit")} - esse pacote ainda não está disponível para a a versão 3.5 do R


```


01 - Bloco de código (chunk) que contém um conjunto de Funções variadas: Cria a data e hora local, com timezone do Brasil;...


```{r 01_funcoes_variadas}

# Função que cria a data e hora local, com timezone do Brasil
# Essa função foi desenvolvida para colocar a informação no formato DATE em formato 'character' no SQLite,
# visto que o SQLite converte data em número.
log_data_hora <- function () {

     format(lubridate::now(), tz ="Brazil/East", usetz = TRUE)

}

###################################################################

valor_monetario <- function (x) {
  
     readr::parse_number(x, locale = locale(grouping_mark = ".",
                                            decimal_mark = ","))

}

###################################################################

url_tcm <- function () {
  
url_tcm <-  "http://www.tcm.ba.gov.br/consulta-de-despesas/"
  
}

###################################################################

url_tcm_entidades_ws <- function(){

url_tcm_entidades_ws <- "http://www.tcm.ba.gov.br/Webservice/index.php/entidades?cdMunicipio="

}

###################################################################



```



02 - Bloco de código (chunk) que contém a Função que Criar o conjunto de pastas de trabalho (diretórios)


```{r 02_criar_diretorios}

criar_diretorios <- function() {

# Cria as pastas dos diretórios que serão utilizados;  

dir_principal <- getwd()

subdir_bd_sqlite <- file.path(dir_principal, "bd_sqlite")
subdir_resposta_scraping_html <- file.path(dir_principal, "resposta_scraping_html")
subdir_resposta_scraping_links <- file.path(dir_principal, "resposta_scraping_links")
subdir_dados_exportados <- file.path(dir_principal, "dados_exportados")

if (dir.exists(dir_principal) == FALSE) {
    dir.create(dir_principal)
}


if (dir.exists(subdir_bd_sqlite) == FALSE) {
    dir.create(subdir_bd_sqlite)
}

if (dir.exists(subdir_resposta_scraping_html) == FALSE) {
    dir.create(subdir_resposta_scraping_html)
}

if (dir.exists(subdir_resposta_scraping_links) == FALSE) {
    dir.create(subdir_resposta_scraping_links)
}

if (dir.exists(subdir_dados_exportados) == FALSE) {
    dir.create(subdir_dados_exportados)
}

print("As pastas foram criadas com sucesso no diretório")


}

```


03 - Bloco de código (chunk) que contém a Função que cria a conexão com o SGBD


```{r 03_conexao_sgbd}


###################################################################

conexao_sgbd <- function() {

# Verifica se o diretório onde ficará o arquivo do SQLite está criado;
if (dir.exists("bd_sqlite") == FALSE) { criar_diretorios() }

# Cria a conexão com o SQLite, assim como o arquivo 'bd_tcm_gastos_municipais.db', caso ele não exista;
drive <- DBI::dbDriver("SQLite")
sqlite_bd <- DBI::dbConnect(drive, dbname = file.path("bd_sqlite", "bd_tcm_gastos_municipais.db"))

print("Conexão com o SQL efetuada com sucesso")

return(sqlite_bd)

}

###################################################################



```



04 - Bloco de código (chunk) que contém a Função que cria as tabelas no SGBD;


```{r 04_criar_tabelas_bd}


criar_tabelas_bd <- function() {
  
conect_bd <- conexao_sgbd()


if (DBI::dbExistsTable(conect_bd, "tabela_dcalendario") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_dcalendario (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    data TEXT NOT NULL,
                                                    ano TEXT NOT NULL,
                                                    mes TEXT NOT NULL
                                                    );"
                                                    )
}



if (DBI::dbExistsTable(conect_bd, "tabela_tcm_dmunicipios") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_tcm_dmunicipios (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    cod_municipio INT NOT NULL,
                                                    nm_municipio TEXT NOT NULL,
                                                    log_create TEXT NOT NULL
                                                    );"
                                                    )
}


if (DBI::dbExistsTable(conect_bd, "tabela_tcm_dmunicipios_entidades") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_tcm_dmunicipios_entidades (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    cod_municipio INT NOT NULL,
                                                    nm_municipio TEXT NOT NULL,
                                                    cod_entidade INT NOT NULL,
                                                    nm_entidade TEXT NOT NULL,
                                                    log_create TEXT NOT NULL
                                                    );"
                                                    )
}


if (DBI::dbExistsTable(conect_bd, "tabela_log_request") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_log_request (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                  	log_erro	TEXT NOT NULL,
                                                  	time	TEXT NOT NULL,
                                                  	foreign_key	INTEGER NOT NULL,
                                                  	nm_entidade	TEXT NOT NULL,
                                                  	pagina	INTEGER NOT NULL,
                                                  	documento	TEXT NOT NULL,
                                                  	link	TEXT NOT NULL
                                                    );"
                                                    )
}



if (DBI::dbExistsTable(conect_bd, "tabela_entidades_alvos_paginas") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_entidades_alvos_paginas (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    ano TEXT NOT NULL,
                                                    cod_municipio INT NOT NULL,
                                                    nm_municipio TEXT NOT NULL,
                                                    cod_entidade INT NOT NULL,
                                                    nm_entidade TEXT NOT NULL,
                                                    pagina INT NOT NULL,
                                                    filtro INT NOT NULL
                                                    );"
                                                    )
}


if (DBI::dbExistsTable(conect_bd, "tabela_paginas_links") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_paginas_links (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    ano TEXT NOT NULL,
                                                    cod_municipio INT NOT NULL,
                                                    nm_municipio TEXT NOT NULL,
                                                    cod_entidade INT NOT NULL,
                                                    nm_entidade TEXT NOT NULL,
                                                    pagina INT NOT NULL,
                                                    status_request_html_pag TEXT NOT NULL,
                                                    log_request_html_pag TEXT NOT NULL,
                                                    nm_arq_html_pag TEXT NOT NULL,
                                                    arq_html_pag_tratado TEXT NOT NULL,
                                                    hash_arq_html_pag TEXT NOT NULL,
                                                    log_tratamento_arq_html_pag TEXT NOT NULL
                                                    );"
                                                    )

}
  
if (DBI::dbExistsTable(conect_bd, "tabela_requisicoes") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_requisicoes (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    ano TEXT NOT NULL,
                                                    cod_municipio INT NOT NULL,
                                                    nm_municipio TEXT NOT NULL,
                                                    cod_entidade INT NOT NULL,
                                                    nm_entidade TEXT NOT NULL,
                                                    pagina INT NOT NULL,
                                                    status_request_html_pag TEXT NOT NULL,
                                                    log_request_html_pag TEXT NOT NULL,
                                                    nm_arq_html_pag TEXT NOT NULL,
                                                    arq_html_pag_tratado TEXT NOT NULL,
                                                    hash_arq_html_pag TEXT NOT NULL,
                                                    log_tratamento_arq_html_pag TEXT NOT NULL,
                                                    documento TEXT NOT NULL,
                                                    empenho TEXT NOT NULL,
                                                    valor_documento TEXT NOT NULL,
                                                    link_despesa TEXT NOT NULL,
                                                    nm_arq_html_despesa TEXT NOT NULL,
                                                    status_request_html_despesa TEXT NOT NULL,
                                                    log_request_html_despesa TEXT NOT NULL,
                                                    arq_html_despesa_tratado TEXT NOT NULL,
                                                    hash_arq_html_despesa TEXT NOT NULL,
                                                    log_tratamento_arq_html_despesa TEXT NOT NULL
                                                    );"
                                                    )
  
}


 if (DBI::dbExistsTable(conect_bd, "tabela_despesas_municipais") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_despesas_municipais (
                                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                                    fase TEXT NOT NULL,
                                                    data_do_pagamento TEXT NOT NULL,
                                                    valor_do_pagamento TEXT NOT NULL,
                                                    documento TEXT NOT NULL,
                                                    empenho TEXT NOT NULL,
                                                    data_empenho TEXT NOT NULL,
                                                    tipo_de_empenho TEXT NOT NULL,
                                                    favorecido TEXT NOT NULL,
                                                    valor_do_empenho TEXT NOT NULL,
                                                    valor_das_retencoes TEXT NOT NULL,
                                                    restos_a_pagar TEXT NOT NULL,
                                                    conta_bancaria TEXT NOT NULL,
                                                    fonte_de_recurso_tcm TEXT NOT NULL,
                                                    fonte_de_recurso_gestor TEXT NOT NULL,
                                                    tipo_de_documento TEXT NOT NULL,
                                                    cod_municipio TEXT NOT NULL,
                                                    municipio TEXT NOT NULL,
                                                    cod_entidade TEXT NOT NULL,
                                                    nm_entidade TEXT NOT NULL,
                                                    poder TEXT NOT NULL,
                                                    orgao TEXT NOT NULL,
                                                    unidade_orcamentaria TEXT NOT NULL,
                                                    funcao TEXT NOT NULL,
                                                    subfuncao TEXT NOT NULL,
                                                    programa TEXT NOT NULL,
                                                    tipo_acao TEXT NOT NULL,
                                                    acao TEXT NOT NULL,
                                                    natureza_da_despesa_tcm TEXT NOT NULL,
                                                    natureza_da_despesa_gestor TEXT NOT NULL,
                                                    fonte_de_recurso_tcm_2 TEXT NOT NULL,
                                                    fonte_de_recurso_gestor_2 TEXT NOT NULL,
                                                    licitacao TEXT NOT NULL,
                                                    dispensa_inexigibilidade TEXT NOT NULL,
                                                    contrato TEXT NOT NULL,
                                                    declaracao TEXT NOT NULL,
                                                    foreign_key INTEGER NOT NULL,
                                                    nm_arq_html_despesa TEXT NOT NULL,
                                                    hash_arq_html_despesa TEXT NOT NULL,
                                                    log_tratamento_arq_html_despesa TEXT NOT NULL,
                                                    link TEXT NOT NULL
                                                    );"
                                                    )
  
}

if (DBI::dbExistsTable(conect_bd, "tabela_despesas_municipais_tidy_data") == FALSE) {

    DBI::dbExecute(conect_bd, "CREATE TABLE tabela_despesas_municipais_tidy_data (
                                                  	id INTEGER NOT NULL,
                                                  	fase TEXT NOT NULL,
                                                  	data_do_pagamento	TEXT NOT NULL,
                                                  	valor_do_pagamento	REAL NOT NULL,
                                                  	documento	TEXT NOT NULL,
                                                  	empenho	TEXT NOT NULL,
                                                  	data_empenho	TEXT NOT NULL,
                                                  	tipo_de_empenho	TEXT NOT NULL,
                                                  	cod_favorecido TEXT NOT NULL,
                                                  	nm_favorecido	TEXT NOT NULL,
                                                  	valor_do_empenho	REAL NOT NULL,
                                                  	valor_das_retencoes	REAL NOT NULL,
                                                  	restos_a_pagar TEXT NOT NULL,
                                                  	conta_bancaria TEXT NOT NULL,
                                                  	cod_fonte_de_recurso_tcm	TEXT NOT NULL,
                                                  	nm_fonte_de_recurso_tcm	TEXT NOT NULL,
                                                  	cod_fonte_de_recurso_gestor	TEXT NOT NULL,
                                                  	nm_fonte_de_recurso_gestor TEXT NOT NULL,
                                                  	tipo_de_documento	TEXT NOT NULL,
                                                  	cod_municipio	TEXT NOT NULL,
                                                  	municipio	TEXT NOT NULL,
                                                  	cod_entidade TEXT NOT NULL,
                                                  	nm_entidade	TEXT NOT NULL,
                                                  	poder	TEXT NOT NULL,
                                                  	cod_orgao	TEXT NOT NULL,
                                                  	nm_orgao TEXT NOT NULL,
                                                  	cod_unidade_orcamentaria	TEXT NOT NULL,
                                                  	nm_unidade_orcamentaria	TEXT NOT NULL,
                                                  	cod_funcao TEXT NOT NULL,
                                                  	nm_funcao	TEXT NOT NULL,
                                                  	cod_subfuncao TEXT NOT NULL,
                                                  	nm_subfuncao TEXT NOT NULL,
                                                  	cod_programa TEXT NOT NULL,
                                                  	nm_programa	TEXT NOT NULL,
                                                  	cod_tipo_acao TEXT NOT NULL,
                                                  	nm_tipo_acao TEXT NOT NULL,
                                                  	cod_acao TEXT NOT NULL,
                                                  	nm_acao	TEXT NOT NULL,
                                                  	cod_natureza_da_despesa_tcm TEXT NOT NULL,
                                                  	nm_natureza_da_despesa_tcm TEXT NOT NULL,
                                                  	cod_natureza_da_despesa_gestor TEXT NOT NULL,
                                                  	nm_natureza_da_despesa_gestor	TEXT NOT NULL,
                                                  	cod_fonte_de_recurso_tcm_2	TEXT NOT NULL,
                                                  	nm_fonte_de_recurso_tcm_2	TEXT NOT NULL,
                                                  	cod_fonte_de_recurso_gestor_2 TEXT NOT NULL,
                                                  	nm_fonte_de_recurso_gestor_2 TEXT NOT NULL,
                                                  	licitacao	TEXT NOT NULL,
                                                  	Dispensa_Inexigibilidade TEXT NOT NULL,
                                                  	contrato TEXT NOT NULL,
                                                  	declaracao TEXT NOT NULL,
                                                  	foreign_key	INTEGER NOT NULL,
                                                  	nm_arq_html_despesa	TEXT NOT NULL,
                                                  	hash_arq_html_despesa	TEXT NOT NULL,
                                                  	log_tratamento_arq_html_despesa	TEXT NOT NULL,
                                                  	link TEXT NOT NULL
                                                    );"
                                                    )
  
}

  DBI::dbDisconnect(conect_bd)

}


```


05 - Bloco de código (chunk) que contém a Função que cria e atualiza a tabela dCalendario no BD

```{r 05_criar_tab_dcalendario}

# Criar a função que gera a tabela com a relação de meses e ano para o Web Scraping;
criar_tb_dcalendario <- function(anos_alvos){

anos_alvos <- as.numeric(anos_alvos)

if(length(anos_alvos) > 1){ 
  
  return(print("Informe apenas um valor: O ano de início para realizar o Web Scraping."))

}

anos_validos <- c(2016, 2017, 2018)

if(!anos_alvos %in% anos_validos){
  
  return(print("Informe um dos seguintes anos: 2016, 2017 ou 2018"))
    
}

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()

tb_dcalendario <- purrr::map_dfr(anos_alvos, tb_anos_alvos) %>%
                  tibble::as.tibble()

DBI::dbWriteTable(conect_bd, "tabela_dcalendario", tb_dcalendario, overwrite = TRUE)

print("A tabela `tabela_dcalendario` foi criada com sucesso no BD")

DBI::dbDisconnect(conect_bd)
  
  
}
 
######################################################################################
  
tb_anos_alvos <- function(anos_alvos) {
  

# Cria a tabela com a relação de meses e ano para o Web Scraping;
tb_calendario <- tibble::tibble(data = seq(ymd(paste0(anos_alvos,"-01-01")), (today() - day(today()) + 1 - months(2)), by = "month"),
                                 ano = year(data),
                                 mes = month(data),
                                 log_create = log_data_hora()) %>%
                  dplyr::mutate(data = as.character(data),
                  # A coluna 'data', 'ano' e 'mês' foram transformados em 'character' 
                  # para ser registrada no SQLite como TEXT, já que ele não suporta o formato DATE;
                                ano = as.character(ano),
                                mes = as.character(mes))

return(tb_calendario)

}

######################################################################################

```


06 - Bloco de código (chunk) que contém as funções: 'criar_tb_dmunicipios' que gravará o resultado do scraping no BD na tabela 'tabela_tcm_dmunicipios'. E a 'scraping_tcm_municipios', responsável por capturar o código e nome dos municípios;


```{r 06_criar_tab_dmunicipios}

criar_tb_dmunicipios <- function() {

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()

print("Iniciando Web Scraping dos códigos e nomes dos Municípios utilziados pelo TCM-Ba")
  
# Executa o scraping que captura os códigos e nomes dos municípios
tb_tcm_dmunicipios <- scraping_tcm_municipios()


DBI::dbWriteTable(conect_bd, "tabela_tcm_dmunicipios", tb_tcm_dmunicipios, overwrite = TRUE)


print("A tabela `tabela_tcm_dmunicipios` foi criado com sucesso no BD")

DBI::dbDisconnect(conect_bd)

}


######################################################################################


scraping_tcm_municipios <- function() {

# Scraping do código e nome dos municípios, e por meio do qual será feio o scraping
url_tcm <- url_tcm()


list_tcm_municipios <- httr::GET(url_tcm) %>% 
                       xml2::read_html() %>% 
                       rvest::html_nodes("#municipio > option") 

cod_municipio <- list_tcm_municipios %>% 
                 rvest::html_attr("value")

nm_municipio <- list_tcm_municipios %>% 
                rvest::html_text() %>% 
                stringr::str_replace(., "[*]", "") %>% 
                stringr::str_trim()

tabela_tcm_dmunicipios <- tibble::tibble(cod_municipio = cod_municipio,
                                         nm_municipio = nm_municipio,
                                         log_create = log_data_hora()) %>%
                          dplyr::filter(cod_municipio != "")

return(tabela_tcm_dmunicipios)


}

######################################################################################



```


07 - Bloco de código (chunk) que contém as funções que:'criar_tb_dmunicipios_entidades' que gravará o resultado do scraping no BD na tabela 'tabela_tcm_dmunicipios_entidades'.E a função 'scraping_tcm_entidades_ws', responsável por capturar o código e nome dos entes muninipais;


```{r 07_criar_tab_dmunicipios_entidades}

criar_tb_dmunicipios_entidades <- function() {

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()  


cod_nm_mun <- DBI::dbReadTable(conect_bd, "tabela_tcm_dmunicipios")


#Gera a tabela com dados dos municípios e entidades, a partir do scraping do WS do TCM-Ba
scraping_mun_ent <- purrr::pmap_dfr(cod_nm_mun, scraping_tcm_entidades_ws)


DBI::dbWriteTable(conect_bd, "tabela_tcm_dmunicipios_entidades", scraping_mun_ent, overwrite = TRUE)


print("A tabela `tabela_tcm_dmunicipios_entidades` foi criado com sucesso no BD")

DBI::dbDisconnect(conect_bd)

}

######################################################################################


scraping_tcm_entidades_ws <- function(cod_municipio, nm_municipio, log_create) {

# URL do Web Service do TCM-Ba;
url_tcm_entidades_ws <- url_tcm_entidades_ws()

# Scraping do código e nome dos entes municipais via Web Service;
resultado <- paste0(url_tcm_entidades_ws, cod_municipio) %>%
             httr::GET() %>%
             httr::content() %>%
             purrr::map_dfr(tibble::as_tibble)


# Tratamento dos dados obtidos via Web Service;
tratar_resultado <- resultado %>%
                    magrittr::set_names(c("cod_entidade", "nm_entidade")) %>%
                    dplyr::mutate(cod_municipio = cod_municipio, nm_municipio = nm_municipio,
                                  log_create = log_data_hora()) %>%
                    dplyr::mutate_all(stringr::str_to_upper) %>%
                    dplyr::mutate_all(stringr::str_trim) %>%
                    dplyr::select(cod_municipio, nm_municipio, cod_entidade, nm_entidade, log_create)


# Print para visualizar a progressão do scraping
print(paste("Scraping:", tratar_resultado$cod_municipio, "-", tratar_resultado$nm_municipio,
            "-", tratar_resultado$cod_entidade, "-", tratar_resultado$nm_entidade))


# Função return() para que o output seja o dataframe que está na variável 'tratar_resultado';
return(tratar_resultado)

}

######################################################################################


```


08 -  Bloco de código (chunk) que contém a Função que cria a tabela das entidades alvos

```{r 08_criar_tb_entidades_alvos_paginas}


criar_tb_entidades_alvos_paginas <- function(anos_alvos, cod_municipios_alvos){

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()

criar_diretorios()

criar_tb_dcalendario(anos_alvos)


tb_dcalendario <- DBI::dbReadTable(conect_bd, "tabela_dcalendario") %>%
                  dplyr::select("ano") %>%
                  tibble::as.tibble() %>%
                  dplyr::distinct()
                                  

tb_municipios_alvos_novos <- DBI::dbReadTable(conect_bd, "tabela_tcm_dmunicipios_entidades") %>%
                             dplyr::filter(cod_municipio %in% cod_municipios_alvos) %>%
                             dplyr::mutate(pagina = "1") %>%
                             dplyr::select("cod_municipio", "nm_municipio",
                                           "cod_entidade", "nm_entidade", "pagina") %>%
                             tibble::as.tibble()
                         
# Essa parte do código foi um armenge, em virtude de não ter conseguido colocar o ano para expandir
# na rotina antior. Trocar por alguma função do dplyr
tb_municipios_alvos_novos <- merge.data.frame(tb_dcalendario, tb_municipios_alvos_novos) %>%
                             dplyr::mutate(filtro = paste0(ano, cod_municipio)) %>%
                             dplyr::arrange(desc(ano)) %>%
                             tibble::as.tibble()


tb_municipios_alvos_anteriores <- DBI::dbReadTable(conect_bd, "tabela_entidades_alvos_paginas") %>%
                                  dplyr::mutate(filtro = paste0(ano, cod_municipio)) %>%
                                  tibble::as.tibble()


tb_municipios_alvos_atualizada <- tb_municipios_alvos_novos %>%
  # o sinal ! antes de cod_municipio é um
  # operador lógico para excluir os dados da coluna (Lei de De Morgan)
                                  dplyr::filter(!filtro %in% tb_municipios_alvos_anteriores$filtro) %>%
                                  dplyr::arrange(desc(ano))
#!!! Aqui, termina o armengue no código, pois não consegui usar a função dplyr::filter com dois critérios como um.
# No futuro, subistituir o techo aciima pelo debaixo que está comentado.


# tb_municipios_alvos_atualizada <- tb_municipios_alvos_novos %>%
#                                   dplyr::filter(!cod_municipio %in% cod_muni_ant | !ano %in% ano_ant)%>%
#                                   dplyr::arrange(desc(ano))

DBI::dbWriteTable(conect_bd, "tabela_entidades_alvos_paginas",
                  tb_municipios_alvos_atualizada, append = TRUE)

DBI::dbDisconnect(conect_bd)

print("Tabela 'tabela_entidades_alvos_paginas' gerada com sucesso!")

}


```




09 - Bloco de código (chunk) que contém a Função do Web Scraping para obter as páginas e links das depesas


```{r 09_scraping_tab_paginas_links, message=FALSE, warning=FALSE}


executar_scraping_num_pags <- function() {

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()

entidades_alvos <- DBI::dbReadTable(conect_bd, "tabela_entidades_alvos_paginas")

print("Iniciando Web Scraping das páginas_links das entidades alvos!")

purrr::pwalk(entidades_alvos, scraping_num_pags)

print("Web Scraping das páginas_links das entidades alvos finalizado!")

DBI::dbDisconnect(conect_bd)

}


######################################################################################

scraping_num_pags <- function(id, ano, cod_municipio, nm_municipio,
                              cod_entidade, nm_entidade, pagina, ...) {


  if (dir.exists(file.path("resposta_scraping_links", nm_municipio)) == FALSE) {
  dir.create(file.path("resposta_scraping_links", nm_municipio))
  }
      
  if (dir.exists(file.path("resposta_scraping_links", nm_municipio, nm_entidade)) == FALSE) {
  dir.create(file.path("resposta_scraping_links", nm_municipio, gsub("/", "", nm_entidade)))
  }
  
  
  repeat {
    
      # Cria a conexão com o SGBD;
      conect_bd <- conexao_sgbd()
      
      site_tcm <- paste0("http://www.tcm.ba.gov.br/consulta-de-despesas/?pg=", pagina,
                        "&txtEntidade=&ano=", ano,
                        "&favorecido=&entidade=", cod_entidade,
                        "&orgao=&orcamentaria=&despesa=&recurso=&desp=P&dtPeriodo1=&dtPeriodo2=")
        

      scraping_tcm_paginas <- httr::GET(site_tcm)
      
      
      # Grava a hora e data da requisição para ser incluída no arquivo HMTL e no BD 
      log_request <- log_data_hora()
  
      
      # Verifica se há tabela, pelo seu tamanho, no HTML.
      # Servirá como gatilho de parar o repeat quando chegar na última página
      gatinho_to_break <- scraping_tcm_paginas %>%
                          xml2::read_html() %>%
                          rvest::html_node("#tabelaResultado") %>%
                          rvest::html_table() %>%
                          .$Documento %>%
                          length() 
  
      # Se o gatilho de verificação for igual a 0, então ele pula para a próxima entidade municipal
    if (gatinho_to_break == 0 ) { 
        
        print(paste("Fim das requisições de", nm_entidade, "na Página", pagina))
            
        break
            
}

      
    # Gera o nome do arquivo
      nm_arq_html_pag <- paste0(ano, "-", cod_entidade,
                                "-pag_", pagina, "_", ".html")
      
      tb_pag_links <- DBI::dbReadTable(conect_bd, "tabela_paginas_links")
      

      
    if (nm_arq_html_pag %in% tb_pag_links$nm_arq_html_pag & gatinho_to_break < 20) {
        
        
        print(paste("Fim das requisições de", nm_entidade, "na Página", pagina, "- P"))
        
        break
        
}
      

    if (nm_arq_html_pag %in% tb_pag_links$nm_arq_html_pag & gatinho_to_break == 20) {
        
        print(paste0("Scraping - ", nm_entidade, " - ", ano," - Página: ", pagina, "- Continuação"))
        
        pegar_paginas <- scraping_tcm_paginas %>%
                         xml2::read_html() %>%
                         rvest::html_nodes("#tabelaResultado") %>%
                         xml2::write_html(file.path("resposta_scraping_links", nm_municipio,
                                                    gsub("/", "", nm_entidade), nm_arq_html_pag))       
          
       # Gera o Hash do Arquivo HTML que foi gravado
        hash_arq_html <- git2r::hashfile(file.path("resposta_scraping_links", nm_municipio,
                                                   gsub("/", "", nm_entidade), nm_arq_html_pag))
        
        pagina <- pagina + 1
      
        DBI::dbExecute(conect_bd, 'UPDATE tabela_entidades_alvos_paginas 
                                   SET pagina = :pagina
                                   WHERE id = :id',
                       params = list(pagina = as.character(pagina),
                                     id = as.character(id)))
        
        DBI::dbExecute(conect_bd, 'UPDATE tabela_paginas_links 
                                   SET arq_html_pag_tratado = "N",
                                       hash_arq_html_pag = :hash_arq_html
                                   WHERE nm_arq_html_pag = :nm_arq_html_pag',
                       params = list(hash_arq_html = as.character(hash_arq_html),
                                     nm_arq_html_pag = as.character(nm_arq_html_pag)))
        
        DBI::dbDisconnect(conect_bd)
        
        break
        
        
    } else {
       
      
       pegar_paginas <- scraping_tcm_paginas %>%
                        xml2::read_html() %>%
                        rvest::html_nodes("#tabelaResultado") %>%
                        xml2::write_html(file.path("resposta_scraping_links", nm_municipio,
                                                    gsub("/", "", nm_entidade), nm_arq_html_pag))       
          
       # Gera o Hash do Arquivo HTML que foi gravado
       hash_arq_html <- git2r::hashfile(file.path("resposta_scraping_links", nm_municipio,
                                                   gsub("/", "", nm_entidade), nm_arq_html_pag)) 
          
       tb_paginas_links <- tibble::tibble(ano = ano,
                                     cod_municipio = cod_municipio,
                                     nm_municipio = nm_municipio,
                                     cod_entidade = cod_entidade,
                                     nm_entidade = nm_entidade,
                                     pagina = pagina,
                                     status_request_html_pag = "S",
                                     log_request_html_pag = log_request,
                                     nm_arq_html_pag = nm_arq_html_pag,
                                     arq_html_pag_tratado = "N",
                                     hash_arq_html_pag = hash_arq_html,
                                     log_tratamento_arq_html_pag = "")
       
       DBI::dbWriteTable(conect_bd, "tabela_paginas_links", tb_paginas_links, append = TRUE)

       
}       
       
   print(paste0("Scraping - ", nm_entidade, " - ", ano," - Página: ", pagina))
       
       
   if (gatinho_to_break < 20) {
   
   pagina <- pagina
       
}
   
   if (gatinho_to_break == 20) {
   
   pagina <- pagina + 1
       
}
       
  
DBI::dbExecute(conect_bd, 'UPDATE tabela_entidades_alvos_paginas 
                           SET pagina = :pagina
                           WHERE id = :id',
              params = list(pagina = as.character(pagina),
                            id = as.character(id)))

DBI::dbDisconnect(conect_bd)
     

}     
        
 
}


######################################################################################



```


10 - Bloco de código (chunk) que contém a Função que cria a tabela de requisições


```{r 10_criar_tb_requisicoes_despesas}

######################################################################################

criar_tb_requisicoes_despesas <- function() {
  
  # Cria a conexão com o SGBD;
  conect_bd <- conexao_sgbd()
    

  tab_html_num_pags <- DBI::dbReadTable(conect_bd, "tabela_paginas_links") %>%
                       dplyr::filter(arq_html_pag_tratado == "N")
  
  
  purrr::pwalk(tab_html_num_pags, parser_arq_html_pags)
  
  print("Tabela de requisições criada com sucesso")
  
  DBI::dbDisconnect(conect_bd)

}


######################################################################################


parser_arq_html_pags <- function(id, ano, cod_municipio, nm_municipio,
                                 cod_entidade, nm_entidade, pagina,
                                 status_request_html_pag, log_request_html_pag,
                                 nm_arq_html_pag, hash_arq_html_pag, ...) {

  # Cria a conexão com o SGBD;
  conect_bd <- conexao_sgbd()
  

  # Registra o horário do parser para ser usado como registro do log na coluna 'log_tratamento_arq_html_pag'
  log_parser <- log_data_hora()
  
  # Realiza o parser no arquivo HTML
  parser_arq_html <- xml2::read_html(file.path("resposta_scraping_links", nm_municipio,
                                               gsub("/", "", nm_entidade), nm_arq_html_pag))
  
  # Extrai a tabela do arquivo HTML
  convert_html_tab <- parser_arq_html %>%
                      rvest::html_node("#tabelaResultado") %>% 
                      rvest::html_table()
  
  # Extrai os registros da coluna Documento da tabela
  doc_arq_html_pag <- convert_html_tab %>%
                      .$Documento %>%
                      as.character()
  
  # Extrai os registros da coluna Empenho da tabela
  emp_arq_html_pag <- convert_html_tab %>%
                      .$Empenho %>%
                      as.character()
                      
  # Extrai os registros da coluna Valor da tabela
  valor_arq_html_pag <- convert_html_tab %>%
                        .$Valor %>%
                        readr::parse_number(locale = locale(grouping_mark = ".", decimal_mark = ","))
  
  # Extrai os links que estavam que estabam incorporados na tag 'a' da coluna Documento
  link_arq_html_pag <- parser_arq_html %>%
                       rvest::html_nodes("a") %>%
                       rvest::html_attrs() %>%
                       unlist()
  
  
  # Agrega todos os dados para formar a tabela de requisições
  tb_requisicoes <- tibble::tibble(
                                  ano = ano,
                                  cod_municipio = cod_municipio,
                                  nm_municipio = nm_municipio,
                                  cod_entidade = cod_entidade,
                                  nm_entidade = nm_entidade,
                                  pagina = pagina,
                                  status_request_html_pag = status_request_html_pag,
                                  log_request_html_pag = log_request_html_pag,
                                  nm_arq_html_pag = nm_arq_html_pag,
                                  arq_html_pag_tratado = "S",
                                  hash_arq_html_pag = hash_arq_html_pag,
                                  log_tratamento_arq_html_pag = log_parser,
                                  documento = doc_arq_html_pag,
                                  empenho = emp_arq_html_pag,
                                  valor_documento = valor_arq_html_pag,
                                  link_despesa = link_arq_html_pag,
                                  nm_arq_html_despesa = "",
                                  status_request_html_despesa = "N",
                                  log_request_html_despesa = "",
                                  arq_html_despesa_tratado = "N",
                                  hash_arq_html_despesa = "",
                                  log_tratamento_arq_html_despesa = ""
                                  )
  
  # Carrega a 'tabela_requisicoes' para servir de teste lógico na etapa seguinte
  tb_requisicoes_anterior <- DBI::dbReadTable(conect_bd, "tabela_requisicoes") %>%
                             dplyr::filter(cod_entidade == cod_entidade & pagina == pagina)
   
  tb_requisicoes_atualizada <- tb_requisicoes %>%
  # Exclui as URL iguais que já existiam na tabela, proveniente de HTML com informações parciais
                               dplyr::filter(!link_arq_html_pag %in% tb_requisicoes_anterior$link_despesa)
  
  
  # Grava a tabela 'tb_requisicoes' no Bando de Dados na tabela 'tabela_requisicoes'
  DBI::dbWriteTable(conect_bd, "tabela_requisicoes", tb_requisicoes_atualizada, append = TRUE)
  
  
  # Grava "S" na tabela '' para controlar os arquivos HTML já tratados 
  DBI::dbExecute(conect_bd, 'UPDATE tabela_paginas_links 
                             SET arq_html_pag_tratado = "S",
                                 log_tratamento_arq_html_pag = :log_parser
                             WHERE cod_entidade = :cod_entidade AND
                                   pagina = :pagina;',
                 params = list(log_tratamento_arq_html_pag = as.character(log_parser),
                               cod_entidade = as.character(cod_entidade),
                               pagina = as.character(pagina)))
  
  print(paste0("Parser:", pagina, " - ", nm_arq_html_pag, " - ", nm_entidade))
  
  
  DBI::dbDisconnect(conect_bd)
  

}


```



11 - Bloco de código (chunk) que contém a Função que faz o Web Scraping para obter os arquivos HMTL que contêm os Extatos das Despesas 

```{r 11_scraping_html_despesas}

executar_scraping_html_despesas <- function() {
  
  # Cria a conexão com o SGBD;
  conect_bd <- conexao_sgbd()
  

  tb_requisicoes <- DBI::dbReadTable(conect_bd, "tabela_requisicoes") %>%
                    dplyr::filter(status_request_html_despesa == "N")
  
  
  print("Iniciando Web Scraping dos arquivos HTML das Despesas")
  
  
  purrr::pwalk(tb_requisicoes, scraping_html_despesas)
  
  
  print("O Web Scraping dos arquivos HTML das Despesas foi concluído")
  
  
  # Rotina para executar uma segunda tentativa do Scraping
  # para requisitar as URL com timeout ou 404, ou os HTML com inconsistência 
  tb_requisicoes_2 <- DBI::dbReadTable(conect_bd, "tabela_requisicoes") %>%
                      dplyr::filter(status_request_html_despesa == "N")
  

  if (nrow(tb_requisicoes_2) > 0){
    
    print("Segunda tentativa para requisitar as URL com timeout ou 404, ou os HTML com inconsistência")
    
    purrr::pwalk(tb_requisicoes_2, scraping_html_despesas)
  
    print(" A Segunda tentativa do Web Scraping dos arquivos HTML das Despesas foi concluída")
    
    
}

  DBI::dbDisconnect(conect_bd)  

}


######################################################################################


scraping_html_despesas <- function(id, ano, cod_municipio, nm_municipio,
                                   cod_entidade, nm_entidade, pagina,
                                   status_request_html_pag, log_request_html_pag,
                                   nm_arq_html_pag, documento, valor_documento,
                                   link_despesa, ...) {
  
  if (dir.exists(file.path("resposta_scraping_html", nm_municipio)) == FALSE) {
      dir.create(file.path("resposta_scraping_html", nm_municipio))
  }
      
  if (dir.exists(file.path("resposta_scraping_html", nm_municipio, nm_entidade)) == FALSE) {
      dir.create(file.path("resposta_scraping_html", nm_municipio, gsub("/", "", nm_entidade)))
  }

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()
  
log_request <- log_data_hora()

scraping_html_purrr <- purrr::safely(httr::GET)

scraping_html <- scraping_html_purrr(link_despesa, timeout(35))
    

  # Verifica houve timeout. Se sim, esperar 20 segundos e tentar novamente.
if (length(scraping_html$result) == 0) {
  
    print(paste("### Timeout: da Primeira tentativa. Mais uma tentativa será realizada para:",
                nm_arq_html_pag, "- doc:", documento, "###"))
  
     tb_request <- tibble::tibble(
                                  log_erro = "timeout - primeira tentativa",
                                  time = log_request,
                                  foreign_key = id,
                                  nm_entidade = nm_entidade,
                                  pagina = pagina,
                                  documento = documento,
                                  link = link_despesa
                                  )

   
     DBI::dbWriteTable(conect_bd, "tabela_log_request", tb_request, append = TRUE)
     
     Sys.sleep(15)
     
     print(paste("#### Segunda tentativa para:", nm_arq_html_pag,
                 "- doc:", documento, "####"))
        
     # Segunda tentativa. Se houver timeout novamente, pular para a próxima requisição.
     scraping_html <- scraping_html_purrr(link_despesa, timeout(35))
  
          if (length(scraping_html$result) == 0) {
      
              tb_request <- tibble::tibble(
                                          log_erro = "timeout - segunda tentativa",
                                          time = log_request,
                                          foreign_key = id,
                                          nm_entidade = nm_entidade,
                                          pagina = pagina,
                                          documento = documento,
                                          link = link_despesa
                                          )
          
               DBI::dbWriteTable(conect_bd, "tabela_log_request", tb_request, append = TRUE)
          
               DBI::dbDisconnect(conect_bd)
               
               # Parar a iteração e pular para a próxima requisição
               return(print(paste("### Timeout: da Segunda tentativa para:", nm_arq_html_pag,
                                  "- doc:", documento, "- Pulando para o próximo link de despesa ###")))
  

}

}


# Verifica se há erro de querisição 404. Se sim, grava o erro numa tabela de log no BD.
if (scraping_html$result$status_code == 404) {

  
     tb_request <- tibble::tibble(
                                  log_erro = "erro - 404",
                                  time = log_request,
                                  foreign_key = id,
                                  nm_entidade = nm_entidade,
                                  pagina = pagina,
                                  documento = documento,
                                  link = link_despesa
                                  )
  
     DBI::dbWriteTable(conect_bd, "tabela_log_request", tb_request, append = TRUE)
     
     DBI::dbDisconnect(conect_bd)
  
     # Parar a iteração e pular para a próxima requisição.
     return(print(paste("### Erro 404 de Requisição para:",
                         nm_arq_html_pag, "- doc:", documento,
                        "- Pulando para o próximo link de desepesa ###")))
 
        
}


# Realiza um teste no HTML para saber se os dados estão completos, ou se houve erro durante a resposta do TCM
# scraping_html$result é proveniente da função 'scraping_html_purrr'
  teste_html_despesas <- scraping_html$result %>%
                         xml2::read_html() %>%
                         rvest::html_nodes("label+ span") %>%
                         rvest::html_text() %>%
                         stringr::str_trim()
  
  # Primeiro critério que será usado no teste de integridade do arquivo HTML
  teste_1 <- "-"
  

if (teste_html_despesas[8] == teste_1) {
  # Retirei o critério 'teste_html_despesas[13] == teste_1', pois o arquivo está com 
  # a informação '-' na base de dados do TCM
  
    tb_request <- tibble::tibble(
                                 log_erro = "HTML de despesa incompleto",
                                 time = log_request,
                                 id = id,
                                 nm_entidade = nm_entidade,
                                 pagina = pagina,
                                 documento = documento,
                                 link = link_despesa
                                 )

   DBI::dbWriteTable(conect_bd, "tabela_log_request", tb_request, append = TRUE)
   
   DBI::dbDisconnect(conect_bd)

   return(print(paste("### O HTML", nm_arq_html_pag, "- doc:",
                      documento, "não está com informações completas. Tentar mais tarde. ###")))
   
     
# Se tudo estiver OK com a requisição e com o arquivo HTML, então executa esse bloco de código.
  } else {
      
  # Salva o arquivo HTML no HD para ser tratado por outra função    
    nome_arquivo_html <- paste0(ano, "-", cod_entidade,
                                "-pag_", pagina, "-doc_", documento,
                                "-val_", valor_documento, "_.html")

        if (file.exists(file.path("resposta_scraping_html", nm_municipio,
                                     gsub("/", "", nm_entidade), nome_arquivo_html)) == TRUE) {
    
              sufixo <- format(Sys.time(), "%H_%M_%S")
              
              nome_arquivo_html <- paste0(gsub("_.html", "", nome_arquivo_html),
                                          "-d_", sufixo, "_.html")
            
}
              
    
    # scraping_html$result é proveniente da função 'scraping_html_purrr'
    pegar_html_despesas <- scraping_html$result %>%
                           xml2::read_html() %>%
                           rvest::html_node("div.col-xs-12.content.padding_content") %>%
                           xml2::write_html(file.path("resposta_scraping_html", nm_municipio,
                                                      gsub("/", "", nm_entidade), nome_arquivo_html))

    
    # Gera o Hash do Arquivo HTML que foi gravado
    hash_arq_html_despesa <- git2r::hashfile(file.path("resposta_scraping_html", nm_municipio,
                                                       gsub("/", "", nm_entidade), nome_arquivo_html))
    

    
    # Grava "S" na tabela 'tabela_paginas_links' para controlar os arquivos HTML já tratados 
    DBI::dbExecute(conect_bd, 'UPDATE tabela_requisicoes 
                               SET status_request_html_despesa = "S",
                                   nm_arq_html_despesa = :nome_arquivo_html,
                                   log_request_html_despesa = :log_request,
                                   hash_arq_html_despesa = :hash_arq_html_despesa
                               WHERE id = :id;',
                   params = list(nome_arquivo_html = as.character(nome_arquivo_html),
                                 log_request = as.character(log_request),
                                 hash_arq_html_despesa = as.character(hash_arq_html_despesa),
                                 id = as.character(id)))
    
    DBI::dbDisconnect(conect_bd)
    
    print(paste("Scraping -", "Ano:", ano, "- Pág:", pagina, "- Doc:", documento, 
                  "- Valor:", valor_documento, "-", nm_entidade))

}

    
}


######################################################################################


```



12 - Bloco de código (chunk) que contém a Função que faz o parser e o Data Munging dos arquivos HMTL que contêm os Extatos das Despesas. E função que transforma os dados no padrão Tidy, armazenando-os em uma tabela no BD e exportando em arquivos CSV.



```{r 12_data_wrangling_html_despesas}

executar_data_wrangling_html_despesas <- function() {
  
# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()

tb_requisicoes <- DBI::dbReadTable(conect_bd, "tabela_requisicoes") %>%
                  dplyr::filter(arq_html_despesa_tratado == "N" & nm_arq_html_despesa != "")
  
DBI::dbDisconnect(conect_bd)
  
  if (nrow(tb_requisicoes) == 0) {
    
        print("Todos os Arquivos HTML das despesas já foram tratados")
    
    } else {

        purrr::pwalk(tb_requisicoes, data_wrangling_html_despesas)
        
        print("Todos os Arquivos HTML das despesas já foram tratados")

}

  
}


######################################################################################


data_wrangling_html_despesas <- function(id, ano, cod_municipio, nm_municipio,
                                cod_entidade, nm_entidade, pagina,
                                status_request_html_pag, log_request_html_pag,
                                nm_arq_html_pag, documento, valor_documento,
                                link_despesa, nm_arq_html_despesa,
                                hash_arq_html_despesa,
                                log_tratamento_arq_html_despesa, ...){

 # Realiza o parser no arquivo HTML
parser_arq_html <- xml2::read_html(file.path("resposta_scraping_html", nm_municipio,
                                             gsub("/", "", nm_entidade), nm_arq_html_despesa),
                                   encoding = "UTF-8")


pegar_dados_html <- parser_arq_html %>%
                    rvest::html_nodes("label+ span") %>%
                    rvest::html_text() %>%
                    stringr::str_trim()


log_parser_arq_html_despesa <- log_data_hora()

  
tb_despesas_municipais <- tibble::tibble(
                                        fase = pegar_dados_html[1],
                                        data_do_pagamento = pegar_dados_html[2],
                                        valor_do_pagamento = pegar_dados_html[3],
                                        documento = pegar_dados_html[4],
                                        empenho = pegar_dados_html[5],
                                        data_empenho = pegar_dados_html[6],
                                        tipo_de_empenho = pegar_dados_html[7],
                                        favorecido = pegar_dados_html[8],
                                        valor_do_empenho = pegar_dados_html[9],
                                        valor_das_retencoes = pegar_dados_html[10],
                                        restos_a_pagar = pegar_dados_html[11],
                                        conta_bancaria = pegar_dados_html[12],
                                        fonte_de_recurso_tcm = pegar_dados_html[13],
                                        fonte_de_recurso_gestor = pegar_dados_html[14],
                                        tipo_de_documento = pegar_dados_html[15],
                                        # Enriqueci a tabela com o dado do código do município
                                        cod_municipio = cod_municipio,
                                        municipio = pegar_dados_html[16],
                                        # Enriqueci a tabela com o dado do código da entidade municipal
                                        cod_entidade = cod_entidade,
                                        nm_entidade = pegar_dados_html[17],
                                        poder = pegar_dados_html[18],
                                        orgao = pegar_dados_html[19],
                                        unidade_orcamentaria = pegar_dados_html[20],
                                        funcao = pegar_dados_html[21],
                                        subfuncao = pegar_dados_html[22],
                                        programa = pegar_dados_html[23],
                                        tipo_acao = pegar_dados_html[24],
                                        acao = pegar_dados_html[25],
                                        natureza_da_despesa_tcm = pegar_dados_html[26],
                                        natureza_da_despesa_gestor = pegar_dados_html[27],
                                        fonte_de_recurso_tcm_2 = pegar_dados_html[28],
                                        fonte_de_recurso_gestor_2 = pegar_dados_html[29],
                                        licitacao = pegar_dados_html[30],
                                        dispensa_inexigibilidade = pegar_dados_html[31],
                                        contrato = pegar_dados_html[32],
                                        declaracao = pegar_dados_html[33],
                                        foreign_key = id,
                                        nm_arq_html_despesa = nm_arq_html_despesa,
                                        hash_arq_html_despesa = hash_arq_html_despesa,
                                        log_tratamento_arq_html_despesa = log_parser_arq_html_despesa,
                                        link = link_despesa
                                        )
                                      

# Cria a conexão com o SGBD;
conect_bd <- conexao_sgbd()


DBI::dbWriteTable(conect_bd, "tabela_despesas_municipais", tb_despesas_municipais, append = TRUE)


# Grava "S" na tabela 'tabela_requisicoes' para controlar os arquivos HTML já tratados 
DBI::dbExecute(conect_bd, 'UPDATE tabela_requisicoes
                           SET arq_html_despesa_tratado = "S",
                               log_tratamento_arq_html_despesa = :log_parser_arq_html_despesa
                           WHERE id = :id;',
               params = list(log_parser_arq_html_despesa = as.character(log_parser_arq_html_despesa),
                             id = as.character(id)))


DBI::dbDisconnect(conect_bd)


return(print(paste("Tratado:", nm_arq_html_despesa, "-", nm_entidade)))


}


######################################################################################


executar_tidy_data <- function() {

  # Cria a conexão com o SGBD.
  conect_bd <- conexao_sgbd()

  
  tb_despesas_municipios <- DBI::dbReadTable(conect_bd, "tabela_despesas_municipais") %>%
                            tibble::as.tibble() %>%
                            tidyr::separate(col = favorecido,
                                            into = c("cod_favorecido",
                                                     "nm_favorecido"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%    
                            tidyr::separate(col = fonte_de_recurso_tcm,
                                            into = c("cod_fonte_de_recurso_tcm",
                                                     "nm_fonte_de_recurso_tcm"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = fonte_de_recurso_gestor,
                                            into = c("cod_fonte_de_recurso_gestor",
                                                     "nm_fonte_de_recurso_gestor"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = orgao,
                                            into = c("cod_orgao",
                                                     "nm_orgao"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = unidade_orcamentaria,
                                            into = c("cod_unidade_orcamentaria",
                                                     "nm_unidade_orcamentaria"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = funcao,
                                            into = c("cod_funcao",
                                                     "nm_funcao"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>% 
                            tidyr::separate(col = subfuncao,
                                            into = c("cod_subfuncao",
                                                     "nm_subfuncao"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>% 
                            tidyr::separate(col = programa,
                                            into = c("cod_programa",
                                                     "nm_programa"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>% 
                            tidyr::separate(col = tipo_acao,
                                            into = c("cod_tipo_acao",
                                                     "nm_tipo_acao"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = acao,
                                            into = c("cod_acao",
                                                     "nm_acao"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>% 
                            tidyr::separate(col = natureza_da_despesa_tcm,
                                            into = c("cod_natureza_da_despesa_tcm",
                                                     "nm_natureza_da_despesa_tcm"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = natureza_da_despesa_gestor,
                                            into = c("cod_natureza_da_despesa_gestor",
                                                     "nm_natureza_da_despesa_gestor"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = fonte_de_recurso_tcm_2,
                                            into = c("cod_fonte_de_recurso_tcm_2",
                                                     "nm_fonte_de_recurso_tcm_2"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            tidyr::separate(col = fonte_de_recurso_gestor_2,
                                            into = c("cod_fonte_de_recurso_gestor_2",
                                                     "nm_fonte_de_recurso_gestor_2"),
                                            sep = " - ",
                                            remove = TRUE, extra = "merge") %>%
                            dplyr::mutate(valor_das_retencoes = stringr::str_replace(valor_das_retencoes, "-", "0")) %>%
                            dplyr::mutate(tipo_de_documento = stringr::str_replace(tipo_de_documento, "[º]", ".")) %>%
                            dplyr::mutate_at(vars(valor_do_pagamento, valor_das_retencoes,
                                                  valor_do_empenho), ~valor_monetario(.)) %>%
                            dplyr::mutate_at(vars(data_do_pagamento, data_empenho), ~lubridate::dmy(.)) %>%
                            dplyr::mutate_at(vars(fase:declaracao), ~stringr::str_to_upper(.)) %>%
                            dplyr::mutate_all(stringr::str_trim) %>%
                            dplyr::mutate_all(funs(stringi::stri_trans_general(., "latin-ascii")))


DBI::dbWriteTable(conect_bd, "tabela_despesas_municipais_tidy_data", tb_despesas_municipios, overwrite = TRUE)

print("Os dados foram colocados no padrão Tidy Data e salvos no Bando de Dados em 'tabela_despesas_municipais_tidy_data'")

DBI::dbDisconnect(conect_bd)


readr::write_delim(tb_despesas_municipios, file.path("dados_exportados",
                                                     "tabela_despesas_municipais_tidy_data.csv"), delim = ";")

print("Os dados foram colocados no padrão Tidy Data Internacional e salvos em CSV no diretório 'dados_exportados'")


tb_despesas_municipios_BR <- tb_despesas_municipios %>%
                             dplyr::mutate_at(vars(valor_das_retencoes, valor_do_pagamento,
                                                   valor_do_empenho), ~stringr::str_replace(., "[.]", ","))


readr::write_delim(tb_despesas_municipios_BR, file.path("dados_exportados",
                                                        "tabela_despesas_municipais_tidy_data_BR.csv"), delim = ";")

print("Os dados foram colocados no padrão Tidy Data Brasil (R$) e salvos em CSV no diretório 'dados_exportados'")


}


######################################################################################


```


- Área de Execução para teste do código


```{r executar, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}


# Variável que define a partir de que ano os dados serão raspados.
anos_alvos <- c("2018")

# Variável que define os municípios (e respectios entes municipais) serão raspados.
# Web Scraping das entidades municipais somente do Município de Salvador (Prefeitura, Câmara e Adm. Indireta)
cod_municipios <- c(2928703)

# Web Scraping das entidades municipais dos Municípios de:
# Santo Antõnio de Jesus, Santo Amaro, Nazaré, Porto Seguro, Ilhéus, Barreiras, São Francisco do Conde e Salvador
#cod_municipios <- c(2928703, 2928604, 2922508, 2925303, 2913606, 2903201, 2929206, 2927408)

# Função que cria as pastas dos arquivos
criar_diretorios()

# Função que cria 4 tabelas que serão armazenadas no SQLite.
criar_tabelas_bd()

# Função que cria a tabela dCalendario
criar_tb_dcalendario(anos_alvos)

# Função que faz o Web Scraping do código e nome dos Municípios
criar_tb_dmunicipios()

# Função que faz o Web Scraping (via Web Service) do código e nome das Entidades e, ao fim, cria a tabela.
criar_tb_dmunicipios_entidades()

# Função que cria a tabela das entidades alvos, controlando a paginação por cod_municipio e Ano.
criar_tb_entidades_alvos_paginas(anos_alvos, cod_municipios)

# Função executa o Web Scraping das páginas que têm os links que darão acesso
# as páginas HTML que contêm os dados sobre as despesas
executar_scraping_num_pags()

# Função que Cria a tabela central para Controle das Requisições dos HTML que contêm
# as informções sobre as despesas municipais
criar_tb_requisicoes_despesas()

# Função cria a tabela de requisições e faz o Web Scraping das páginas HTML que contêm
# os dados das despesas. #OBS: O tempo de resposta do TCM está entre 10 a 30 segundos
executar_scraping_html_despesas()

# Função que faz o parser dos HTMLs das depesas e o Data Wrangling dos HTMLs
executar_data_wrangling_html_despesas()

# Função que faz o pré-processamento dos dados obtidos do HTML, aplicando o conceito Tidy Data 
# Por fim, cria uma tabela no padrão Tidy Data no BD e exporta dois arquivos CSV para a pasta
# dados_exportados. Um arquivo no padrão Tidy Internacional e outro no padrão Brasil (R$).
executar_tidy_data()

# O conceito Tidy Data de Hadley Wickham tem por objetivo arrumar os dados
# para que eles sejam utilizados em softwares de estatísticas ou
# de Business Intelligence sem a necessidade de realizar
# mais transformações nos dados.

# O Conceito está resumido nestas três regras:
# - Cada variável deve ter sua própria coluna.
# - Cada observação deve ter sua própria linha.
# - Cada valor deve ter sua própria célula.

#(http://r4ds.had.co.nz/tidy-data.html)

```



- Área que indica os BUGs a serem corrigidos, e as Melhorias, Implementações e Testes que precisam ser feitas no Código.


```{r eval=FALSE, include=FALSE}

######################################################################################

# PRIORIDADES
#!!! Implantar o Docker do RStudio no Digital Ocean;


# MELHORIAS
#!!! Verificar a necessidade de evitar a sobrescrição de arquivos HMTL das páginas_links, colocando um sufixo ao final;
#!!! Na função 'executar_tidy_data', substituir os "-" que aparecem em 'fonte_de_recurso_tcm' e 'fonte_de_recurso_gestor'
#    pelos valores que estão em "fonte_de_recurso_tcm_2" e 'fonte_de_recurso_gestor_2'
#!!! Implementar uma rotina para evitar timeout nos Webs Scrapings que estão
#    contidos nas funções 'criar_tb_dmunicipios_entidades' e 'criar_tb_dmunicipios'
#!!! Implementar rotina para tratar erro de falta de conexão com a internet
#!!! Procurar uma solução no pacote dplyr ou tibble para o 'armengue' feito na função 'criar_tb_entidades_alvos_paginas'
#    com a função merge.data.frame e verificar se há um método de filtro no dplyr::filter, para que não seja necessário
#    criar a coluna 'filtro'
#!!! Colocar uma coluna na tabela_log para registrar os erros de requisição. Para isso, temos que analisar como
#    é a resposta HTML do código do TCM
#!!! Analisar a melhor prática de programação para conectar, escrever e desconectar no BD. Talvez uma solução seja
#    colocar a função de conexão do banco de dados dentro da função de escrita, em vez de colocar a variável
#    'conect_bd'



# IMPLEMENTAÇÕES
# NO CÓDIGO
#!!! Documentar todo o código;
#!!! Definir a melhor forma de encademaneto na execução das funções primárias para
#    iniciar e continuar o Web Scraping. Além disso, estabelecer rotinas de check no momento de 
#    fazer o input do anos_alvos e cod_municipio
#!!! Finalizar o Código para que se torne automatizado com o CronR/CronTab
#    http://leg.ufpr.br/~walmes/ensino/web-scraping/li%C3%A7%C3%B5es/13-crontab/
#!!! Paralelizar requisições e o tratamento de dados com o pacote `furrr` ou com a função abjutils::pvec() ;
#!!! Atribuir cor aos prints;
#!!! Desenvolver o Packrat do Web Scraping;
#!!! Implementar uma Função de backup do BD e dos arquivos HTML raspados;
#    em uma pasta do OneDrive;
#!!! Implementar um API com o pacote 'Plumber';
#!!! Desenvolver um Pacote R para o Web Scraping do TCM-Ba. Incluir uma tabela com o código e nome
#    dos municípios e entidades municipais
#!!! Gerar 'alertas' sobre os pagamentos para publicar no Facebook, Telegram ou Facebook
#    Ex: Despesas de festas em perídos não festivos; Ou emitir relatório resumido na forma de imagem
#    para ser enviado via Telegram, após obter os dados completos do mês;
#!!! Adequar o código para aceitar conexão com o MySQL, PostgreSQL e MongoDB;
#- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
# NA INFRAESTRUTURA
#!!! Implantar o Docker do RStudio no Digital Ocean, definindo o Volume para armazenar o SQLite;
#!!! Implantar o Docker do RStudio com o Packrat do Web Scraping;


# FALTA TESTAR
#!!! A abordagem para evitar a criação de links de requisição já existeste na 'tabela_requisicoes'
#    ao tratar páginas de despesas que deixaram de ter menos de 20 links, após a complementação
#    dos dados pelo ente municipal. Realizei um commit em relação a essa etapa;


######################################################################################

```
